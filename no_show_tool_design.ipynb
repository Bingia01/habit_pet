{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddab2796",
   "metadata": {},
   "source": [
    "# Orthopedic No-Show Prevention Tool\n",
    "This notebook demonstrates a thin-slice of the predictive and reporting tool requested by the orthopedic service line. It is built on synthetic data for illustration, yet every step mirrors what we will deploy once real encounter-level data (with `SCH_STATE_DISPLAY`, `NO_SHOW_FLAG`, reminders, etc.) becomes available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0b4872",
   "metadata": {},
   "source": [
    "### Context & guiding principles\n",
    "- Focus on *at-scheduling* risk so staff can intervene days before the appointment.\n",
    "- Favor interpretable baselines (logistic regression + permutation importance) and only layer tree ensembles when they offer material lift.\n",
    "- Keep artifacts clinic-friendly: individual patient call lists and aggregate day-of-clinic drill downs.\n",
    "- All results below use `Synthetic_Patient_Dataset_with_Target.csv` (n=25). Treat numbers as placeholders; the code scaffolding is what matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1555f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.base import clone\n",
    "\n",
    "sns.set_theme(style='ticks', palette='deep')\n",
    "pd.set_option('display.max_columns', 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f1937b",
   "metadata": {},
   "source": [
    "## 1. Load synthetic encounter-level data\n",
    "In production the extract will land from HealtheIntent / Encounter tables with the critical fields listed in the implementation memo. For prototyping we reuse the evidence-based synthetic file generated earlier in the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f2659",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path = Path('data/Synthetic_Patient_Dataset_with_Target.csv')\n",
    "df = pd.read_csv(\n",
    "    data_path,\n",
    "    parse_dates=['BIRTH_DT_TM', 'APPT_START_DATE', 'APPOINTMENT_SCHEDULED_DATE']\n",
    ")\n",
    "print(f\"Records: {len(df)} | Columns: {df.shape[1]}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06b08c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "target_counts = df['APPOINTMENT_STATUS'].value_counts()\n",
    "ax.bar(target_counts.index, target_counts.values, color=['#2ca02c', '#d62728', '#1f77b4'])\n",
    "ax.set_title('Observed appointment outcomes (synthetic)')\n",
    "ax.set_ylabel('Count of appointments')\n",
    "ax.set_xticklabels(target_counts.index, rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('No-show + cancellation rate:', f\"{df['no_show_binary'].mean():.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdccf6db",
   "metadata": {},
   "source": [
    "## 2. Feature engineering blueprint\n",
    "We engineer only features that would exist at scheduling time so the model stays actionable. Additional elements (prior no-shows, reminder logs, ADI score) will be merged once supplied by the data warehouse team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccedbb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_model = df.copy()\n",
    "\n",
    "df_model['appointment_month'] = df_model['APPT_START_DATE'].dt.month\n",
    "df_model['appointment_week'] = df_model['APPT_START_DATE'].dt.isocalendar().week.astype(int)\n",
    "df_model['appointment_dayofweek_name'] = df_model['APPT_START_DATE'].dt.day_name()\n",
    "df_model['lead_time_bucket'] = pd.cut(\n",
    "    df_model['lead_time_days'],\n",
    "    bins=[0, 7, 14, 21, 60],\n",
    "    labels=['≤7d', '8-14d', '15-21d', '>21d'],\n",
    "    include_lowest=True\n",
    ").astype(str)\n",
    "\n",
    "numeric_features = [\n",
    "    'patient_age',\n",
    "    'lead_time_days',\n",
    "    'appointment_month',\n",
    "    'appointment_week',\n",
    "    'is_new_patient',\n",
    "    'is_follow_up'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'PRIMARY_INSURANCE',\n",
    "    'PRIMARY_PLAN_TYPE',\n",
    "    'ATTENDING_SPECIALTY',\n",
    "    'SCH_REASON_DISPLAY',\n",
    "    'LOC_FACILITY_DISPLAY',\n",
    "    'age_group',\n",
    "    'SEX',\n",
    "    'RACE',\n",
    "    'ETHNIC_GROUP',\n",
    "    'appointment_dayofweek_name',\n",
    "    'lead_time_bucket'\n",
    "]\n",
    "\n",
    "feature_columns = numeric_features + categorical_features\n",
    "X = df_model[feature_columns]\n",
    "y = df_model['no_show_binary']\n",
    "\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41fe477",
   "metadata": {},
   "source": [
    "## 3. Train/test split and candidate models\n",
    "We benchmark an interpretable logistic regression (balanced class weights) against a Gradient Boosting Classifier. With real data we will add cross-site validation, temporal splits, and potentially XGBoost/LightGBM if they materially outperform while maintaining explainability via SHAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ce02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression (balanced)': Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('clf', LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear'))\n",
    "    ]),\n",
    "    'Gradient Boosting': Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('clf', GradientBoostingClassifier(random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "results = []\n",
    "fitted_models = {}\n",
    "roc_curves = {}\n",
    "pr_curves = {}\n",
    "\n",
    "for name, pipe in models.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    fitted_models[name] = pipe\n",
    "\n",
    "    probs = pipe.predict_proba(X_test)[:, 1]\n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, probs)\n",
    "    pr_auc = average_precision_score(y_test, probs)\n",
    "    fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, probs)\n",
    "\n",
    "    roc_curves[name] = (fpr, tpr)\n",
    "    pr_curves[name] = (recall, precision)\n",
    "\n",
    "    results.append({'model': name, 'roc_auc': roc_auc, 'pr_auc': pr_auc})\n",
    "\n",
    "    print(f\"\n",
    "{name}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.3f} | PR AUC: {pr_auc:.3f}\")\n",
    "    print(classification_report(y_test, preds, target_names=['Kept', 'No-Show'], zero_division=0))\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='roc_auc', ascending=False)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689ee8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "for name, (fpr, tpr) in roc_curves.items():\n",
    "    axes[0].plot(fpr, tpr, label=f\"{name}\")\n",
    "axes[0].plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "axes[0].set_title('ROC curves (synthetic split)')\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].legend()\n",
    "\n",
    "for name, (recall, precision) in pr_curves.items():\n",
    "    axes[1].plot(recall, precision, label=f\"{name}\")\n",
    "axes[1].set_title('Precision-Recall curves')\n",
    "axes[1].set_xlabel('Recall')\n",
    "axes[1].set_ylabel('Precision')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c2555e",
   "metadata": {},
   "source": [
    "## 4. Interpretability guardrails\n",
    "The clinical teams asked for an interpretable solution. We therefore keep Logistic Regression as the reference model and use both coefficients and permutation importance to surface the drivers. With real data we will complement this view with SHAP summary plots and fairness dashboards (e.g., compare calibration across zip codes / payer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569fc7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_model = fitted_models['Logistic Regression (balanced)']\n",
    "feature_names = log_model.named_steps['preprocess'].get_feature_names_out()\n",
    "coefficients = log_model.named_steps['clf'].coef_[0]\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefficients,\n",
    "    'abs_coefficient': np.abs(coefficients)\n",
    "}).sort_values('abs_coefficient', ascending=False).head(10)\n",
    "\n",
    "print('Top logistic coefficients (positive => higher no-show odds)')\n",
    "coef_df[['feature', 'coefficient']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702588e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "perm = permutation_importance(\n",
    "    log_model,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    n_repeats=25,\n",
    "    random_state=42\n",
    ")\n",
    "imp_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': perm.importances_mean\n",
    "}).sort_values('importance', ascending=False).head(10)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.barplot(data=imp_df, x='importance', y='feature', ax=ax, color='#1f77b4')\n",
    "ax.set_title('Permutation importance (logistic baseline)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74598e3",
   "metadata": {},
   "source": [
    "## 5. Operational reporting prototypes\n",
    "Supervisors asked for clarity on *how* the predictions will be used. Below we mock the two core artifacts:\n",
    "1. **Patient-level action list** – ranked roster for call center / care navigators.\n",
    "2. **Clinic-day overview** – aggregate risk by clinic day and facility to guide overbooking or reminder intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "production_model = clone(log_model)\n",
    "production_model.fit(X, y)\n",
    "\n",
    "df_scores = df_model.copy()\n",
    "df_scores['predicted_no_show_prob'] = production_model.predict_proba(X)[:, 1]\n",
    "df_scores['risk_band'] = pd.cut(\n",
    "    df_scores['predicted_no_show_prob'],\n",
    "    bins=[0, 0.15, 0.3, 1],\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "columns_to_show = [\n",
    "    'APPT_START_DATE', 'PATIENT_PERSON_ID', 'PRIMARY_INSURANCE',\n",
    "    'SCH_REASON_DISPLAY', 'lead_time_days', 'LOC_FACILITY_DISPLAY',\n",
    "    'predicted_no_show_prob', 'risk_band'\n",
    "]\n",
    "\n",
    "individual_view = df_scores[columns_to_show].sort_values(\n",
    "    by='predicted_no_show_prob', ascending=False\n",
    ").head(10)\n",
    "individual_view['predicted_no_show_prob'] = (individual_view['predicted_no_show_prob'] * 100).round(1)\n",
    "individual_view.rename(columns={'predicted_no_show_prob': 'risk_percent'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b619902",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agg_day = df_scores.groupby('APPT_START_DATE').agg(\n",
    "    appointments=('ENCNTR_ID', 'count'),\n",
    "    avg_pred=('predicted_no_show_prob', 'mean'),\n",
    "    high_risk=('predicted_no_show_prob', lambda x: (x >= 0.30).sum())\n",
    ").reset_index()\n",
    "agg_day['avg_pred_pct'] = (agg_day['avg_pred'] * 100).round(1)\n",
    "\n",
    "agg_facility = df_scores.groupby('LOC_FACILITY_DISPLAY').agg(\n",
    "    appointments=('ENCNTR_ID', 'count'),\n",
    "    avg_pred=('predicted_no_show_prob', 'mean')\n",
    ").reset_index().sort_values('avg_pred', ascending=False)\n",
    "agg_facility['avg_pred_pct'] = (agg_facility['avg_pred'] * 100).round(1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "axes[0].bar(agg_day['APPT_START_DATE'], agg_day['avg_pred_pct'], color='#ff7f0e')\n",
    "axes[0].set_title('Daily mean predicted no-show %')\n",
    "axes[0].set_ylabel('Predicted no-show %')\n",
    "axes[0].set_xlabel('Appointment date')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "for idx, row in agg_day.iterrows():\n",
    "    axes[0].text(row['APPT_START_DATE'], row['avg_pred_pct'] + 0.2, f\"n={row['appointments']}\", ha='center', fontsize=8)\n",
    "\n",
    "axes[1].barh(agg_facility['LOC_FACILITY_DISPLAY'], agg_facility['avg_pred_pct'], color='#1f77b4')\n",
    "axes[1].set_title('Facility-level mean risk')\n",
    "axes[1].set_xlabel('Predicted no-show %')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "agg_day[['APPT_START_DATE', 'appointments', 'avg_pred_pct', 'high_risk']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e893e24b",
   "metadata": {},
   "source": [
    "## 6. Next steps for production data\n",
    "- Request the missing operational fields (scheduling timestamp, reminder channel, prior no-shows) highlighted in the implementation memo and rerun the notebook to validate lift.\n",
    "- Expand evaluation to time-based splits (train on months 1-3, test on 4-6) to mimic go-live.\n",
    "- Promote the notebook into a scheduled pipeline (Databricks or hospital ETL) that refreshes scores daily and writes them to a governance-reviewed table for Power BI/Tableau dashboards.\n",
    "- Layer on fairness monitoring (e.g., compare calibration curves by insurance category or ADI quartile) before exposing the tool to frontline staff."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
